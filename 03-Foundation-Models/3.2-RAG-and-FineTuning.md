# D3.2 RAG and Fine-Tuning (Domain 3: 28% Exam Weight)

## 1. Core Concept: The Media Company Analogy ðŸŽ¬
**Analogy Focus:** When the **Genius Writer (Amazon Bedrock)** needs to create a specialized script based on proprietary company information (like HR policy or historical sales data), we have two main methods:
1.  **Retrieval Augmented Generation (RAG):** Is like having the writer ask the **Super Librarian (Amazon Kendra)** to instantly pull the relevant reference documents from the **Infinite Warehouse (Amazon S3)** and hand them over just before writing. The model does *not* learn this new information permanently.
2.  **Fine-Tuning:** Is like taking the Genius Writer and sending them to a specialized, intensive **training course** using thousands of company-specific documents. The writer's core knowledge and style are permanently adapted for that specific corporate tone or task.

---

## 2. Key Services & Definitions

* **Amazon Bedrock (The Genius Writer):** The service used to access Foundation Models (FMs). It is the environment where both the **RAG request** is executed and where the **fine-tuned model** is hosted for inference.
* **Amazon Kendra (The Super Librarian):** A highly accurate, intelligent search service often used in a RAG architecture to efficiently retrieve context from enterprise documents to augment the prompt.
* **Amazon S3 (The Infinite Warehouse):** Used to store large volumes of data (the knowledge base) that RAG queries or the Fine-Tuning process will rely upon.
* **AWS Glue (The Data Plumber):** May be used to clean, prepare, and transform proprietary data stored in Amazon S3 before it is used for Fine-Tuning or indexed for RAG.

---

## 3. Exam Focus & Key Concepts

* **Retrieval Augmented Generation (RAG):** A method of customizing an FM where the model is provided with **external, retrieved knowledge** (facts, figures, documents) at inference time.
    * **Goal:** To ground the model's output in specific, authoritative, and current external data, preventing **hallucinations** (model making up facts).
    * **Model Training:** **No model training is involved**. The model weights remain unchanged.
    * **Data Flow:** User Query $\rightarrow$ Retrieve relevant documents from data store $\rightarrow$ Augment prompt with documents $\rightarrow$ Send augmented prompt to FM $\rightarrow$ Model generates response.
* **Fine-Tuning:** The process of taking a pre-trained Foundation Model and training it further on a **smaller, labeled dataset** specific to a downstream task (e.g., classifying customer support tickets or translating industry jargon).
    * **Goal:** To permanently adapt the model's parameters/weights, resulting in better performance on a very specific task or dataset.
    * **Model Training:** **Model training is involved**. The model's parameters are permanently adjusted.
    * **Techniques:** Includes methods like **Reinforcement Learning from Human Feedback (RLHF)**, which collects human feedback to further fine-tune the model.
    * **Data Preparation:** Requires careful **curation, governance, size, and labeling** of the training data.

---

## 4. ðŸ§  Interactive Flashcard Quiz

<details>
<summary><strong>Q1: Which customization approach involves adjusting the model's weights and requires model training?</strong> (Click to check)</summary>
> **Answer:** Fine-Tuning
</details>

<details>
<summary><strong>Q2: In a RAG application, which AWS service acts as the "Super Librarian" for efficiently searching enterprise documents?</strong> (Click to check)</summary>
> **Answer:** Amazon Kendra (The Super Librarian)
</details>

<details>
<summary><strong>Q3: What is the primary advantage of using RAG over zero-shot prompting when answering questions about a companyâ€™s proprietary documents?</strong> (Click to check)</summary>
> **Answer:** RAG grounds the answer in specific, verifiable, and current external data, which reduces the chance of model hallucinations.
</details>